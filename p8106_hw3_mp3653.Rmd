---
title: "Homework 3"
author: "Matthew Perrotta"
date: "April 10, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load Libraries
```{r echo = T, message = FALSE, results='hide', warning=FALSE}
library(ISLR)
library(tidyverse)
library(caret)
library(corrplot)
library(pROC)
library(MASS)
```

```{r}
data(Weekly)

x = model.matrix(Direction~., Weekly)[,3:8]

y = Weekly$Direction
```

# Problem (a)
EDA
```{r}
featurePlot(x, 
            y,
            scales = list(x=list(relation="free"), 
                        y=list(relation="free")),
            plot = "density", pch = "|", 
            auto.key = list(columns = 2))

corrplot::corrplot(cor(Weekly[2:8]))
```

All predictors are normally distributed except for `Volume`, which is right skewed. Also, according to the correlation plot, there is no collinearity between predictors.

# Problem (b)
Logistic Regression
```{r}
glm.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
               data = Weekly, 
               family = binomial)

summary(glm.fit)
```

The predictor `Lag2` is the only significant predictor with a p value of 0.0296.


# Problem (c)
Confusion Matrix
```{r}
set.seed(1)
rowTrain <- createDataPartition(y,
                                p = 0.75,
                                list = FALSE)

test.pred.prob  <- predict(glm.fit, newdata = Weekly[-rowTrain,],
                           type = "response")
test.pred <- rep("Down", length(test.pred.prob))
test.pred[test.pred.prob > 0.5] <- "Up"

confusionMatrix(data = as.factor(test.pred),
                reference = Weekly$Direction[-rowTrain],
                positive = "Up")
```

The confusion matrix displays correct and incorrect predictions along the diagonals. The model `glm.fit` made 7 incorrect predictions and 135 correct predictions. The model has a total accuracy of 52.21%


# Problem (d)
ROC Curve
```{r}
roc.glm <- roc(y[-rowTrain], test.pred.prob)

plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm), col = 4, add = TRUE)
```

AUC = 0.500

# Problem (e)

```{r}
train = subset(Weekly, Year >= 1990 & Year <= 2008)
test = subset(Weekly, Year > 2008)

trX = train[,2:3]

trY = train$Direction

teX = test[,2:3]

teY = test$Direction
```

```{r}
glm.fit2 <- glm(Direction ~ Lag1 + Lag2, 
               data = train, 
               family = binomial)

summary(glm.fit2)
```

```{r}
test.pred.prob2  <- predict(glm.fit2, teX,
                           type = "response")
test.pred2 <- rep("Down", length(test.pred.prob2))
test.pred2[test.pred.prob2 > 0.5] <- "Up"
```

```{r}
roc.glm2 <- roc(teY, test.pred.prob2)

plot(roc.glm2, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm2), col = 4, add = TRUE)
```

AUC = 0.556

# Problem (f)

LDA
```{r}
lda.fit <- lda(Direction ~ Lag1 + Lag2, data = train)
```

```{r}
lda.pred <- predict(lda.fit, newdata = teX)

roc.lda <- roc(teY, lda.pred$posterior[,2], 
               levels = c("Down", "Up"))

plot(roc.lda, legacy.axes = TRUE, print.auc = TRUE)
```

AUC = 0.557

QDA
```{r}
qda.fit <- qda(Direction ~ Lag1 + Lag2, data = train)
```

```{r}
qda.pred <- predict(qda.fit, newdata = teX)

roc.qda <- roc(teY, qda.pred$posterior[,2], 
               levels = c("Down", "Up"))

plot(roc.qda, legacy.axes = TRUE, print.auc = TRUE)
```

AUC = 0.529

# Problem (g)

KNN
```{r warning=FALSE}
set.seed(1)

ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

model.knn <- train(trX,
                   trY,
                   method = "knn",
                   preProcess = c("center","scale"),
                   tuneGrid = data.frame(k = seq(1,20,by = 1)),
                   trControl = ctrl)
```
k = 7

```{r}
knn.pred <- predict(model.knn, newdata = teX, type = 'prob')[, 2]

roc.knn <- roc(teY, knn.pred)

plot(roc.knn, legacy.axes = TRUE, print.auc = TRUE)
```

AUC = 0.545

```{r}
auc <- c(roc.glm$auc[1], roc.glm2$auc[1], roc.lda$auc[1],
         roc.qda$auc[1], roc.knn$auc[1])

plot(roc.glm, legacy.axes = TRUE)
plot(roc.glm2, col = 2, add = TRUE)
plot(roc.lda, col = 3, add = TRUE)
plot(roc.qda, col = 4, add = TRUE)
plot(roc.knn, col = 6, add = TRUE)
modelNames <- c("glm","glm2","lda","qda","knn")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:6, lwd = 2)
```

The greater the area under the ROC the better the model, with the best possible model having an AUC of 1. From the models produced above, LDA has the highest AUC and is therefore the better model of those tested. It should be noted that the two predictors `Lga1` and `Lga2` are not significantly associated with the response variable at an alpha of 0.05. While insignificant, they're p values are close enough to still consider these variables as useful predictors.
